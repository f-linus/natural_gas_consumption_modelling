{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../../\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from src.data_handling import ingestion\n",
    "\n",
    "sns.set_theme(context=\"paper\", font_scale=1.15, style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\ba\\lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "d:\\anaconda3\\envs\\ba\\lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "d:\\anaconda3\\envs\\ba\\lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "d:\\anaconda3\\envs\\ba\\lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "ts_data = ingestion.read_combined().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2250, 8), (2250,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = ts_data.drop(columns=[\"consumption\"]), ts_data[\"consumption\"].values\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = MinMaxScaler()\n",
    "ss = StandardScaler()\n",
    "\n",
    "X_trans = ss.fit_transform(X)\n",
    "y_trans = mm.fit_transform(y.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(X, y, n_steps_x, n_steps_y):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_x\n",
    "        out_end_ix = end_ix + n_steps_y\n",
    "        # check if we are beyond the dataset\n",
    "        if out_end_ix > len(X):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = X[i:end_ix], y[end_ix:out_end_ix]\n",
    "        Xs.append(seq_x)\n",
    "        ys.append(seq_y)\n",
    "    return np.array(Xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2101, 100, 8), (2101, 50, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ss, y_mm = create_sequences(X_trans, y_trans, 100, 50)\n",
    "X_ss.shape, y_mm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shapes: (1800, 100, 8) (1800, 50, 1)\n",
      "Testing shapes: (301, 100, 8) (301, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "total_samples = X.shape[0]\n",
    "train_test_cutoff = int(total_samples * 0.8)\n",
    "\n",
    "X_train, X_test = X_ss[:train_test_cutoff], X_ss[train_test_cutoff:]\n",
    "y_train, y_test = y_mm[:train_test_cutoff], y_mm[train_test_cutoff:]\n",
    "\n",
    "print(\"Training shapes:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing shapes:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape: torch.Size([1800, 100, 8]) torch.Size([1800, 50, 1])\n",
      "Testing Shape: torch.Size([301, 100, 8]) torch.Size([301, 50, 1])\n"
     ]
    }
   ],
   "source": [
    "X_train_tensors = Variable(torch.Tensor(X_train))\n",
    "X_test_tensors = Variable(torch.Tensor(X_test))\n",
    "\n",
    "y_train_tensors = Variable(torch.Tensor(y_train))\n",
    "y_test_tensors = Variable(torch.Tensor(y_test))\n",
    "\n",
    "# (number of sequences, number of intances (days) per sequence, number of features in each instance)\n",
    "print(\"Training Shape:\", X_train_tensors.shape, y_train_tensors.shape)\n",
    "print(\"Testing Shape:\", X_test_tensors.shape, y_test_tensors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # LSTM model\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=0.2,\n",
    "        )\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc_1 = nn.Linear(hidden_size, 128)\n",
    "\n",
    "        # Fully connected last layer\n",
    "        self.fc_2 = nn.Linear(128, num_classes)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # hidden state\n",
    "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size))\n",
    "\n",
    "        # cell state\n",
    "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size))\n",
    "\n",
    "        # Propagate input through LSTM\n",
    "        output, (hn, cn) = self.lstm(\n",
    "            x, (h_0, c_0)\n",
    "        )  # (input, hidden, and internal state)\n",
    "        hn = hn.view(-1, self.hidden_size)\n",
    "        out = self.relu(hn)\n",
    "        out = self.fc_1(out)  # first dense\n",
    "        out = self.relu(out)  # relu\n",
    "        out = self.fc_2(out)  # final output\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, lstm, optimiser, loss_fn, X_train, y_train, X_test, y_test):\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        lstm.train()\n",
    "        outputs = lstm.forward(X_train)  # forward pass\n",
    "        optimiser.zero_grad()  # calculate the gradient, manually setting to 0\n",
    "\n",
    "        # obstain the loss function\n",
    "        loss = loss_fn(outputs, y_train)\n",
    "        loss.backward()  # calculate the loss of the loss function\n",
    "        optimiser.step()  # improve from loss, i.e backdrop\n",
    "\n",
    "        # test loss\n",
    "        lstm.eval()\n",
    "        test_preds = lstm(X_test)\n",
    "        test_loss = loss_fn(test_preds, y_test)\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(\n",
    "                f\"Epoch: {epoch}, train loss: {loss.item()}, test loss: {test_loss.item()}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.001\n",
    "\n",
    "input_size = 8\n",
    "hidden_size = 4\n",
    "num_layers = 1\n",
    "\n",
    "num_classes = 50\n",
    "\n",
    "lstm = LSTM(num_classes, input_size, hidden_size, num_layers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
